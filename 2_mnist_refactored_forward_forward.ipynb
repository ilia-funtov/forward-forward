{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rework of https://github.com/mohammadpz/pytorch_forward_forward.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "elif use_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 256\n",
    "test_batch_size = 1000\n",
    "\n",
    "train_kwargs = {'batch_size': train_batch_size, 'shuffle': False}\n",
    "test_kwargs = {'batch_size': test_batch_size, 'shuffle': False}\n",
    "cuda_kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    train_kwargs |= cuda_kwargs\n",
    "    test_kwargs |= cuda_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transform)\n",
    "\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                    transform=transform)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = len(dataset1.classes)\n",
    "data_item_size = dataset1.data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(nn.Linear):\n",
    "    def __init__(self, in_features, out_features,\n",
    "                 bias=True, device=None, dtype=None):\n",
    "        super().__init__(in_features, out_features, bias, device, dtype)\n",
    "        self.opt = Adam(self.parameters(), lr=0.03)\n",
    "        self.threshold = 2.0\n",
    "        self.num_epochs = 10\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-6)\n",
    "        return torch.relu(super().forward(x_direction))            \n",
    "\n",
    "    def train(self, x_pos: torch.Tensor, x_neg: torch.Tensor):\n",
    "        for _ in range(self.num_epochs):\n",
    "            g_pos = self.forward(x_pos).pow(2).mean(1)\n",
    "            g_neg = self.forward(x_neg).pow(2).mean(1)\n",
    "            # The following loss pushes pos (neg) samples to\n",
    "            # values larger (smaller) than the self.threshold.\n",
    "            loss = torch.log(1 + torch.exp(torch.cat([\n",
    "                -g_pos + self.threshold,\n",
    "                g_neg - self.threshold]))).mean()\n",
    "            self.opt.zero_grad()\n",
    "            # this backward just compute the derivative and hence\n",
    "            # is not considered backpropagation.\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "        return self.forward(x_pos).detach(), self.forward(x_neg).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dims, class_num, device):\n",
    "        assert len(dims) >= 1\n",
    "        assert class_num > 0\n",
    "        super().__init__()\n",
    "        self.class_num = class_num\n",
    "        self.layers = [Layer(in_features=(dims[n] + (class_num if n == 0 else 0)), out_features=dims[n + 1], device=device) for n in range(len(dims) - 1)]\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        x_max = x.max()\n",
    "        goodness_per_label = torch.zeros(batch_size, self.class_num, device=x.device)\n",
    "        for k, label in enumerate(range(self.class_num)):\n",
    "            one_hot_label = torch.zeros(batch_size, self.class_num, device=x.device)\n",
    "            one_hot_label[range(batch_size), label] = x_max\n",
    "            h = torch.cat((one_hot_label, x), 1)\n",
    "            goodness = torch.zeros(len(self.layers), batch_size, device=x.device)\n",
    "            for l, layer in enumerate(self.layers):\n",
    "                h = layer(h)\n",
    "                assert isinstance(h, torch.Tensor)\n",
    "                goodness[l] = h.pow(2).mean(1)\n",
    "            goodness_per_label[:, k] = torch.sum(goodness, dim=0)\n",
    "        \n",
    "        output = torch.zeros(batch_size, self.class_num)\n",
    "        max_label = goodness_per_label.argmax(1)\n",
    "        output[range(batch_size), max_label] = 1.0\n",
    "        return output\n",
    "\n",
    "    def train(self, x: torch.Tensor, labels: torch.Tensor) -> None:        \n",
    "        assert x.shape[0] == labels.shape[0]\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        x_max = x.max()\n",
    "        one_hot_labels = torch.zeros(batch_size, self.class_num, device=x.device)\n",
    "        one_hot_labels_random = torch.zeros_like(one_hot_labels, device=x.device)\n",
    "        one_hot_labels[range(batch_size), labels] = x_max\n",
    "        one_hot_labels_random[range(batch_size), labels[torch.randperm(batch_size, device=x.device)]] = x_max\n",
    "        x_pos = torch.cat((one_hot_labels, x), 1)\n",
    "        x_neg = torch.cat((one_hot_labels_random, x), 1)\n",
    "        h_pos, h_neg = x_pos, x_neg\n",
    "        for layer in self.layers:\n",
    "            assert isinstance(layer, Layer)\n",
    "            h_pos, h_neg = layer.train(h_pos, h_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net: Net, data_loader) -> None:\n",
    "    for x, labels in data_loader:\n",
    "        assert isinstance(x, torch.Tensor)\n",
    "        assert isinstance(labels, torch.Tensor)\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        net.train(x, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader) -> float:\n",
    "    assert callable(model)\n",
    "    assert data_loader is not None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_items = 0\n",
    "        n_match = 0\n",
    "        for data, labels in data_loader:\n",
    "            assert isinstance(data, torch.Tensor)\n",
    "            assert isinstance(labels, torch.Tensor)\n",
    "            assert data.shape[0] == labels.shape[0]\n",
    "\n",
    "            data = data.to(device, non_blocking=True)\n",
    "            model_output = model(data)\n",
    "            \n",
    "            assert isinstance(model_output, torch.Tensor)\n",
    "            assert model_output.shape[0] == labels.shape[0]\n",
    "\n",
    "            for i in range(model_output.shape[0]):\n",
    "                label = labels[i].item()\n",
    "                assert label >= 0 and label < class_num\n",
    "                max_feature_index = torch.argmax(model_output[i])\n",
    "                assert max_feature_index >= 0 and max_feature_index < class_num\n",
    "                if max_feature_index == label:\n",
    "                    n_match += 1\n",
    "                n_items += 1\n",
    "\n",
    "        accuracy = n_match / n_items\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net([math.prod(data_item_size), 500, 500], class_num, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:14<02:11, 14.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:28<01:52, 14.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:42<01:38, 14.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:57<01:25, 14.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:09<01:09, 13.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:22<00:53, 13.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:34<00:39, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:47<00:25, 12.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [02:00<00:12, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:13<00:00, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(10)):\n",
    "    train_net(net, data_loader)\n",
    "    evaluate(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9483"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(net, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
